{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Dataset</th><th>Domain</th><th>No: of Series</th><th>Min. Length</th><th>Max. Length</th><th>Competition</th><th>Multivariate</th><th>Download</th><th>Source</th><th>URL</th><th>Frequency</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>M1</td><td>Multiple</td><td>1001</td><td>15</td><td>150</td><td>Yes</td><td>No</td><td>Yearly</td><td>Makridakis et al., 1982</td><td>https://zenodo.org/record/4656193</td><td>Yearly</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>M1</td><td>Multiple</td><td>1001</td><td>15</td><td>150</td><td>Yes</td><td>No</td><td>Quarterly</td><td>Makridakis et al., 1982</td><td>https://zenodo.org/record/4656154</td><td>Quarterly</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>M1</td><td>Multiple</td><td>1001</td><td>15</td><td>150</td><td>Yes</td><td>No</td><td>Monthly</td><td>Makridakis et al., 1982</td><td>https://zenodo.org/record/4656159</td><td>Monthly</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>M3</td><td>Multiple</td><td>3003</td><td>20</td><td>144</td><td>Yes</td><td>No</td><td>Yearly</td><td>Makridakis and Hibon, 2000</td><td>https://zenodo.org/record/4656222</td><td>Yearly</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>M3</td><td>Multiple</td><td>3003</td><td>20</td><td>144</td><td>Yes</td><td>No</td><td>Quarterly</td><td>Makridakis and Hibon, 2000</td><td>https://zenodo.org/record/4656262</td><td>Quarterly</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>M3</td><td>Multiple</td><td>3003</td><td>20</td><td>144</td><td>Yes</td><td>No</td><td>Monthly</td><td>Makridakis and Hibon, 2000</td><td>https://zenodo.org/record/4656298</td><td>Monthly</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>M3</td><td>Multiple</td><td>3003</td><td>20</td><td>144</td><td>Yes</td><td>No</td><td>Other</td><td>Makridakis and Hibon, 2000</td><td>https://zenodo.org/record/4656335</td><td>Other</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>M4</td><td>Multiple</td><td>100000</td><td>19</td><td>9933</td><td>Yes</td><td>No</td><td>Yearly</td><td>Makridakis et al., 2020</td><td>https://zenodo.org/record/4656379</td><td>Yearly</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>M4</td><td>Multiple</td><td>100000</td><td>19</td><td>9933</td><td>Yes</td><td>No</td><td>Quarterly</td><td>Makridakis et al., 2020</td><td>https://zenodo.org/record/4656410</td><td>Quarterly</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>M4</td><td>Multiple</td><td>100000</td><td>19</td><td>9933</td><td>Yes</td><td>No</td><td>Monthly</td><td>Makridakis et al., 2020</td><td>https://zenodo.org/record/4656480</td><td>Monthly</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>10 rows &times; 11 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#7fed485b1270 10x11>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import urllib\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "from datetime import datetime\n",
    "from distutils.util import strtobool\n",
    "\n",
    "import datatable as dt \n",
    "import pandas as pd \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='ingest.log', encoding='utf-8', level=logging.INFO)\n",
    "\n",
    "\n",
    "df = dt.fread(\"monash-repository.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://zenodo.org/record/4656193'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['URL'][0]\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_tsf_to_dataframe(full_file_path_and_name, replace_missing_vals_with=\"NaN\", value_column_name=\"series_value\"):\n",
    "    '''\n",
    "    Converts the contents in a .tsf file into a dataframe and returns it along with other meta-data of the dataset.\n",
    "    \n",
    "        Parameters:\n",
    "            full_file_path_and_name (str): complete .tsf file path\n",
    "            replace_missing_vals_with (str): a term to indicate the missing values in series in the returning dataframe\n",
    "            value_column_name (str): Any name that is preferred to have as the name of the column containing series values in the returning dataframe\n",
    "    \n",
    "        Returns:\n",
    "            data (pd.DataFrame): load data frame\n",
    "            frequency (str): time series frequency\n",
    "            horizon (int): time series forecasting horizon\n",
    "            missing (bool): whether the dataset contains missing values\n",
    "            equal (bool): whether the series have equal lengths\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    col_names = []\n",
    "    col_types = []\n",
    "    all_data = {}\n",
    "    line_count = 0\n",
    "    frequency = None\n",
    "    forecast_horizon = None\n",
    "    contain_missing_values = None\n",
    "    contain_equal_length = None\n",
    "    found_data_tag = False\n",
    "    found_data_section = False\n",
    "    started_reading_data_section = False\n",
    "\n",
    "    with open(full_file_path_and_name, \"r\", encoding=\"cp1252\") as file:\n",
    "        for line in file:\n",
    "            # Strip white space from start/end of line\n",
    "            line = line.strip()\n",
    "\n",
    "            if line:\n",
    "                if line.startswith(\"@\"):  # Read meta-data\n",
    "                    if not line.startswith(\"@data\"):\n",
    "                        line_content = line.split(\" \")\n",
    "                        if line.startswith(\"@attribute\"):\n",
    "                            if (\n",
    "                                len(line_content) != 3\n",
    "                            ):  # Attributes have both name and type\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            col_names.append(line_content[1])\n",
    "                            col_types.append(line_content[2])\n",
    "                        else:\n",
    "                            if (\n",
    "                                len(line_content) != 2\n",
    "                            ):  # Other meta-data have only values\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            if line.startswith(\"@frequency\"):\n",
    "                                frequency = line_content[1]\n",
    "                            elif line.startswith(\"@horizon\"):\n",
    "                                forecast_horizon = int(line_content[1])\n",
    "                            elif line.startswith(\"@missing\"):\n",
    "                                contain_missing_values = bool(\n",
    "                                    strtobool(line_content[1])\n",
    "                                )\n",
    "                            elif line.startswith(\"@equallength\"):\n",
    "                                contain_equal_length = bool(strtobool(line_content[1]))\n",
    "\n",
    "                    else:\n",
    "                        if len(col_names) == 0:\n",
    "                            raise Exception(\n",
    "                                \"Missing attribute section. Attribute section must come before data.\"\n",
    "                            )\n",
    "\n",
    "                        found_data_tag = True\n",
    "                elif not line.startswith(\"#\"):\n",
    "                    if len(col_names) == 0:\n",
    "                        raise Exception(\n",
    "                            \"Missing attribute section. Attribute section must come before data.\"\n",
    "                        )\n",
    "                    elif not found_data_tag:\n",
    "                        raise Exception(\"Missing @data tag.\")\n",
    "                    else:\n",
    "                        if not started_reading_data_section:\n",
    "                            started_reading_data_section = True\n",
    "                            found_data_section = True\n",
    "                            all_series = []\n",
    "\n",
    "                            for col in col_names:\n",
    "                                all_data[col] = []\n",
    "\n",
    "                        full_info = line.split(\":\")\n",
    "\n",
    "                        if len(full_info) != (len(col_names) + 1):\n",
    "                            raise Exception(\"Missing attributes/values in series.\")\n",
    "\n",
    "                        series = full_info[len(full_info) - 1]\n",
    "                        series = series.split(\",\")\n",
    "\n",
    "                        if len(series) == 0:\n",
    "                            raise Exception(\n",
    "                                \"A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series. Missing values should be indicated with ? symbol\"\n",
    "                            )\n",
    "\n",
    "                        numeric_series = []\n",
    "\n",
    "                        for val in series:\n",
    "                            if val == \"?\":\n",
    "                                numeric_series.append(replace_missing_vals_with)\n",
    "                            else:\n",
    "                                numeric_series.append(float(val))\n",
    "\n",
    "                        if numeric_series.count(replace_missing_vals_with) == len(\n",
    "                            numeric_series\n",
    "                        ):\n",
    "                            raise Exception(\n",
    "                                \"All series values are missing. A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series.\"\n",
    "                            )\n",
    "\n",
    "                        all_series.append(pd.Series(numeric_series).array)\n",
    "\n",
    "                        for i in range(len(col_names)):\n",
    "                            att_val = None\n",
    "                            if col_types[i] == \"numeric\":\n",
    "                                att_val = int(full_info[i])\n",
    "                            elif col_types[i] == \"string\":\n",
    "                                att_val = str(full_info[i])\n",
    "                            elif col_types[i] == \"date\":\n",
    "                                att_val = datetime.strptime(\n",
    "                                    full_info[i], \"%Y-%m-%d %H-%M-%S\"\n",
    "                                )\n",
    "                            else:\n",
    "                                raise Exception(\n",
    "                                    \"Invalid attribute type.\"\n",
    "                                )  # Currently, the code supports only numeric, string and date types. Extend this as required.\n",
    "\n",
    "                            if att_val is None:\n",
    "                                raise Exception(\"Invalid attribute value.\")\n",
    "                            else:\n",
    "                                all_data[col_names[i]].append(att_val)\n",
    "\n",
    "                line_count = line_count + 1\n",
    "\n",
    "        if line_count == 0:\n",
    "            raise Exception(\"Empty file.\")\n",
    "        if len(col_names) == 0:\n",
    "            raise Exception(\"Missing attribute section.\")\n",
    "        if not found_data_section:\n",
    "            raise Exception(\"Missing series information under data section.\")\n",
    "\n",
    "        all_data[value_column_name] = all_series\n",
    "        loaded_data = pd.DataFrame(all_data)\n",
    "\n",
    "        return (\n",
    "            loaded_data,\n",
    "            frequency,\n",
    "            forecast_horizon,\n",
    "            contain_missing_values,\n",
    "            contain_equal_length,\n",
    "        )\n",
    "\n",
    "def parse_monash_df(file):\n",
    "    ''' Function to Parse a Locally Extracted and Downloaded File'''\n",
    "    \n",
    "    loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(file)\n",
    "\n",
    "    logging.info(f'PARSING FILE: {file}...')\n",
    "    logging.info(f\"IDENTIFIED FREQUENCY: {frequency}...\")\n",
    "    logging.info(f\"IDENTIFIED FORECAST HORIZON: {forecast_horizon}\")\n",
    "\n",
    "    parsed_df = pd.DataFrame()\n",
    "\n",
    "    #freq = frequency\n",
    "    if frequency == 'yearly':\n",
    "        freq = 'YS' #year start\n",
    "    elif frequency == 'quarterly':\n",
    "        freq = 'QS' #quarter start\n",
    "    elif frequency == 'monthly':\n",
    "        freq = 'MS'\n",
    "    elif frequency == 'daily':\n",
    "        freq = 'D'\n",
    "\n",
    "\n",
    "    for index,row in tqdm(loaded_data.iterrows()):\n",
    "        \n",
    "        name = row.series_name\n",
    "        #print(name)\n",
    "        values = row.series_value.tolist()\n",
    "        length = len(values)\n",
    "        start = row.start_timestamp\n",
    "        \n",
    "        #print(f'STARTING TIMESTAMP: {start}')\n",
    "        #$print(f'TIMESERIES LENGTH: {length}')\n",
    "        \n",
    "        #print(length)\n",
    "        try:\n",
    "            ds = pd.date_range(start, periods=length, freq=freq)\n",
    "            series_df = pd.DataFrame({'unique_id':name,'ds':ds, 'values':values})\n",
    "        except:\n",
    "            logging.warning(f'FAILED PARSING TIMESERIES: {name}')\n",
    "            series_df = pd.DataFrame()\n",
    "            \n",
    "        #convert date range to datetime and automatically coerce errors\n",
    "        #ds = pd.to_datetime(ds, errors = 'coerce')\n",
    "\n",
    "        \n",
    "        #series_df = pd.DataFrame({'unique_id':name,'ds':ds, 'values':values})\n",
    "        parsed_df = pd.concat([parsed_df, series_df], axis=0)\n",
    "        \n",
    "    return parsed_df\n",
    "\n",
    "# Example Usage\n",
    "#parse_monash_df(\"m1_yearly_dataset.tsf\").head()\n",
    "\n",
    "def retrieve_monash_df(url):\n",
    "    \n",
    "    # Create Soup\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    # Create Soup\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    # Find Download URL from Filename Class\n",
    "    info = soup.select(\"[class~=filename]\")\n",
    "    \n",
    "    # Parse Download Url\n",
    "    download_url = info[0].get('href')\n",
    "    \n",
    "    # Download File\n",
    "    urllib.request.urlretrieve(\"https://zenodo.org\" + download_url, \"tmp.zip\")\n",
    "    \n",
    "# Example Usage\n",
    "#retrieve_monash_df(df['URL'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Domain</th>\n",
       "      <th>No: of Series</th>\n",
       "      <th>Min. Length</th>\n",
       "      <th>Max. Length</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Multivariate</th>\n",
       "      <th>Download</th>\n",
       "      <th>Source</th>\n",
       "      <th>URL</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M4</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>100000</td>\n",
       "      <td>19</td>\n",
       "      <td>9933</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Makridakis et al., 2020</td>\n",
       "      <td>https://zenodo.org/record/4656548</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Weather</td>\n",
       "      <td>Nature</td>\n",
       "      <td>3010</td>\n",
       "      <td>1332</td>\n",
       "      <td>65981</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Sparks et al., 2020</td>\n",
       "      <td>https://zenodo.org/record/4654822</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>COVID Deaths</td>\n",
       "      <td>Nature</td>\n",
       "      <td>266</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Johns Hopkins University, 2020</td>\n",
       "      <td>https://zenodo.org/record/4656009</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Saugeen River Flow</td>\n",
       "      <td>Nature</td>\n",
       "      <td>1</td>\n",
       "      <td>23741</td>\n",
       "      <td>23741</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Daily</td>\n",
       "      <td>McLeod and Gweon, 2013</td>\n",
       "      <td>https://zenodo.org/record/4656058</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>US Births</td>\n",
       "      <td>Nature</td>\n",
       "      <td>1</td>\n",
       "      <td>7305</td>\n",
       "      <td>7305</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Pruim et al., 2020</td>\n",
       "      <td>https://zenodo.org/record/4656049</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset    Domain  No: of Series  Min. Length  Max. Length  \\\n",
       "11                  M4  Multiple         100000           19         9933   \n",
       "30             Weather    Nature           3010         1332        65981   \n",
       "49        COVID Deaths    Nature            266          212          212   \n",
       "54  Saugeen River Flow    Nature              1        23741        23741   \n",
       "55           US Births    Nature              1         7305         7305   \n",
       "\n",
       "   Competition Multivariate Download                          Source  \\\n",
       "11         Yes           No    Daily         Makridakis et al., 2020   \n",
       "30          No           No    Daily             Sparks et al., 2020   \n",
       "49          No          Yes    Daily  Johns Hopkins University, 2020   \n",
       "54          No           No    Daily          McLeod and Gweon, 2013   \n",
       "55          No           No    Daily              Pruim et al., 2020   \n",
       "\n",
       "                                  URL Frequency  \n",
       "11  https://zenodo.org/record/4656548     Daily  \n",
       "30  https://zenodo.org/record/4654822     Daily  \n",
       "49  https://zenodo.org/record/4656009     Daily  \n",
       "54  https://zenodo.org/record/4656058     Daily  \n",
       "55  https://zenodo.org/record/4656049     Daily  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Focus on just a few datasets\n",
    "df = df[df['Frequency'].isin(['Daily'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jfarland/Documents/research/timeseries-benchmarks/data'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path = '/Users/jfarland/Documents/research/timeseries-benchmarks'\n",
    "data_path = project_path + '/data'\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset    Domain  No: of Series  Min. Length  Max. Length Competition  \\\n",
      "7      M4  Multiple         100000           19         9933         Yes   \n",
      "\n",
      "  Multivariate Download                   Source  \\\n",
      "7           No   Yearly  Makridakis et al., 2020   \n",
      "\n",
      "                                 URL Frequency  \n",
      "7  https://zenodo.org/record/4656379    Yearly  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23000it [01:20, 284.50it/s]\n",
      "1it [01:33, 93.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# limit to 1 data set\n",
    "sample_df = df[df['Frequency'].isin(['Daily', 'Monthly', 'Yearly'])]\n",
    "\n",
    "#sample_df = sample_df[sample_df['Multivariate']=='Yes']\n",
    "#sample_df = sample_df[(sample_df['Download']=='Yearly') & (sample_df['Dataset'] == 'M4')]\n",
    "\n",
    "print(sample_df)\n",
    "\n",
    "for index, row in tqdm(sample_df.iterrows()):\n",
    "    \n",
    "    # Make sure current directory is data directory\n",
    "    os.chdir(data_path)\n",
    "    \n",
    "    # Remove Archive File if it already exists in \n",
    "    if os.path.exists(data_path + '/tmp.zip'):\n",
    "        logging.info(f'DELETING EXISTING ARCHIVE FILE...')\n",
    "        os.remove(data_path + '/tmp.zip')\n",
    "        \n",
    "    # Identify url from mapping file\n",
    "    url = row.URL\n",
    "    logging.info(f'RETRIEVING URL: {url}')\n",
    "    \n",
    "    # Retrieve the file from the url\n",
    "    retrieve_monash_df(url)\n",
    "    \n",
    "    if not os.path.exists('staging'):\n",
    "        logging.info(\"STAGING DIRECTORY NOT FOUND, CREATING NEW ONE...\")\n",
    "        os.makedirs('staging')\n",
    "    else:\n",
    "        try:\n",
    "            logging.info(\"STAGING DIRECTORY FOUND, CLEANING AND RECREATING...\")\n",
    "            shutil.rmtree('staging')\n",
    "            os.makedirs('staging')\n",
    "        except OSError as e:\n",
    "            logging.warning(\"Error: %s : %s\" % (dest, e.strerror))\n",
    "        \n",
    "    # Copy Archive File into Staging Directory\n",
    "    shutil.copy('tmp.zip', 'staging')\n",
    "    \n",
    "    # Go into the directory and unpack\n",
    "    os.chdir('staging')\n",
    "        \n",
    "    shutil.unpack_archive('tmp.zip')\n",
    "    \n",
    "    # Find any TSF Files\n",
    "    result = glob.glob('*.{}'.format('tsf'))\n",
    "    \n",
    "    # Find the name of the file \n",
    "    local_name = result[0].split(\".\")[0]\n",
    "    logging.info(f'DATASET NAME: {local_name}...')\n",
    "    \n",
    "    # Parse the DataFrame\n",
    "    local_df = parse_monash_df(result[0])\n",
    "    \n",
    "    # Convert to DataTable\n",
    "    local_df = dt.Frame(local_df)\n",
    "    \n",
    "    os.chdir(data_path)\n",
    "    \n",
    "    if not os.path.exists(local_name):\n",
    "        logging.info(\"DATASET DIRECTORY NOT FOUND, CREATING NEW ONE...\")\n",
    "        os.makedirs(local_name)\n",
    "    else:\n",
    "        try:\n",
    "            logging.info(\"DATASET DIRECTORY FOUND, CLEANING AND RECREATING...\")\n",
    "            shutil.rmtree(local_name)\n",
    "            os.makedirs(local_name)\n",
    "        except OSError as e:\n",
    "            logging.warning(\"Error: %s : %s\" % (dest, e.strerror))\n",
    "        \n",
    "    local_df.to_csv(local_name + '/' + local_name + '.csv')\n",
    "    \n",
    "    \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from distutils.util import strtobool\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Converts the contents in a .tsf file into a dataframe and returns it along with other meta-data of the dataset: frequency, horizon, whether the dataset contains missing values and whether the series have equal lengths\n",
    "#\n",
    "# Parameters\n",
    "# full_file_path_and_name - complete .tsf file path\n",
    "# replace_missing_vals_with - a term to indicate the missing values in series in the returning dataframe\n",
    "# value_column_name - Any name that is preferred to have as the name of the column containing series values in the returning dataframe\n",
    "def convert_tsf_to_dataframe(\n",
    "    full_file_path_and_name,\n",
    "    replace_missing_vals_with=\"NaN\",\n",
    "    value_column_name=\"series_value\",\n",
    "):\n",
    "    col_names = []\n",
    "    col_types = []\n",
    "    all_data = {}\n",
    "    line_count = 0\n",
    "    frequency = None\n",
    "    forecast_horizon = None\n",
    "    contain_missing_values = None\n",
    "    contain_equal_length = None\n",
    "    found_data_tag = False\n",
    "    found_data_section = False\n",
    "    started_reading_data_section = False\n",
    "\n",
    "    with open(full_file_path_and_name, \"r\", encoding=\"cp1252\") as file:\n",
    "        for line in file:\n",
    "            # Strip white space from start/end of line\n",
    "            line = line.strip()\n",
    "\n",
    "            if line:\n",
    "                if line.startswith(\"@\"):  # Read meta-data\n",
    "                    if not line.startswith(\"@data\"):\n",
    "                        line_content = line.split(\" \")\n",
    "                        if line.startswith(\"@attribute\"):\n",
    "                            if (\n",
    "                                len(line_content) != 3\n",
    "                            ):  # Attributes have both name and type\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            col_names.append(line_content[1])\n",
    "                            col_types.append(line_content[2])\n",
    "                        else:\n",
    "                            if (\n",
    "                                len(line_content) != 2\n",
    "                            ):  # Other meta-data have only values\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            if line.startswith(\"@frequency\"):\n",
    "                                frequency = line_content[1]\n",
    "                            elif line.startswith(\"@horizon\"):\n",
    "                                forecast_horizon = int(line_content[1])\n",
    "                            elif line.startswith(\"@missing\"):\n",
    "                                contain_missing_values = bool(\n",
    "                                    strtobool(line_content[1])\n",
    "                                )\n",
    "                            elif line.startswith(\"@equallength\"):\n",
    "                                contain_equal_length = bool(strtobool(line_content[1]))\n",
    "\n",
    "                    else:\n",
    "                        if len(col_names) == 0:\n",
    "                            raise Exception(\n",
    "                                \"Missing attribute section. Attribute section must come before data.\"\n",
    "                            )\n",
    "\n",
    "                        found_data_tag = True\n",
    "                elif not line.startswith(\"#\"):\n",
    "                    if len(col_names) == 0:\n",
    "                        raise Exception(\n",
    "                            \"Missing attribute section. Attribute section must come before data.\"\n",
    "                        )\n",
    "                    elif not found_data_tag:\n",
    "                        raise Exception(\"Missing @data tag.\")\n",
    "                    else:\n",
    "                        if not started_reading_data_section:\n",
    "                            started_reading_data_section = True\n",
    "                            found_data_section = True\n",
    "                            all_series = []\n",
    "\n",
    "                            for col in col_names:\n",
    "                                all_data[col] = []\n",
    "\n",
    "                        full_info = line.split(\":\")\n",
    "\n",
    "                        if len(full_info) != (len(col_names) + 1):\n",
    "                            raise Exception(\"Missing attributes/values in series.\")\n",
    "\n",
    "                        series = full_info[len(full_info) - 1]\n",
    "                        series = series.split(\",\")\n",
    "\n",
    "                        if len(series) == 0:\n",
    "                            raise Exception(\n",
    "                                \"A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series. Missing values should be indicated with ? symbol\"\n",
    "                            )\n",
    "\n",
    "                        numeric_series = []\n",
    "\n",
    "                        for val in series:\n",
    "                            if val == \"?\":\n",
    "                                numeric_series.append(replace_missing_vals_with)\n",
    "                            else:\n",
    "                                numeric_series.append(float(val))\n",
    "\n",
    "                        if numeric_series.count(replace_missing_vals_with) == len(\n",
    "                            numeric_series\n",
    "                        ):\n",
    "                            raise Exception(\n",
    "                                \"All series values are missing. A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series.\"\n",
    "                            )\n",
    "\n",
    "                        all_series.append(pd.Series(numeric_series).array)\n",
    "\n",
    "                        for i in range(len(col_names)):\n",
    "                            att_val = None\n",
    "                            if col_types[i] == \"numeric\":\n",
    "                                att_val = int(full_info[i])\n",
    "                            elif col_types[i] == \"string\":\n",
    "                                att_val = str(full_info[i])\n",
    "                            elif col_types[i] == \"date\":\n",
    "                                att_val = datetime.strptime(\n",
    "                                    full_info[i], \"%Y-%m-%d %H-%M-%S\"\n",
    "                                )\n",
    "                            else:\n",
    "                                raise Exception(\n",
    "                                    \"Invalid attribute type.\"\n",
    "                                )  # Currently, the code supports only numeric, string and date types. Extend this as required.\n",
    "\n",
    "                            if att_val is None:\n",
    "                                raise Exception(\"Invalid attribute value.\")\n",
    "                            else:\n",
    "                                all_data[col_names[i]].append(att_val)\n",
    "\n",
    "                line_count = line_count + 1\n",
    "\n",
    "        if line_count == 0:\n",
    "            raise Exception(\"Empty file.\")\n",
    "        if len(col_names) == 0:\n",
    "            raise Exception(\"Missing attribute section.\")\n",
    "        if not found_data_section:\n",
    "            raise Exception(\"Missing series information under data section.\")\n",
    "\n",
    "        all_data[value_column_name] = all_series\n",
    "        loaded_data = pd.DataFrame(all_data)\n",
    "\n",
    "        return (\n",
    "            loaded_data,\n",
    "            frequency,\n",
    "            forecast_horizon,\n",
    "            contain_missing_values,\n",
    "            contain_equal_length,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    series_name start_timestamp  \\\n",
      "0            T1      1972-01-01   \n",
      "1            T2      1974-01-01   \n",
      "2            T3      1974-01-01   \n",
      "3            T4      1974-01-01   \n",
      "4            T5      1976-01-01   \n",
      "..          ...             ...   \n",
      "176        T177      1974-01-01   \n",
      "177        T178      1973-01-01   \n",
      "178        T179      1973-01-01   \n",
      "179        T180      1975-01-01   \n",
      "180        T181      1975-01-01   \n",
      "\n",
      "                                          series_value  \n",
      "0    [3600.0, 7700.0, 12300.0, 30500.0, 47390.0, 57...  \n",
      "1    [12654.0, 22879.0, 34164.0, 49524.0, 64761.0, ...  \n",
      "2    [2142.0, 12935.0, 19130.0, 30500.0, 48177.0, 5...  \n",
      "3    [5774.0, 7650.0, 9271.0, 21447.0, 28998.0, 409...  \n",
      "4    [432312.0, 569011.0, 862673.0, 1155640.0, 1439...  \n",
      "..                                                 ...  \n",
      "176  [290783.0, 285242.0, 293718.0, 295804.0, 29458...  \n",
      "177  [11693.0, 11702.0, 11703.0, 11557.0, 11951.0, ...  \n",
      "178  [8438.0, 8689.0, 8590.0, 8763.0, 8710.0, 8837....  \n",
      "179  [55.91, 54.7, 55.3, 55.75, 55.46, 55.37, 53.82...  \n",
      "180  [564.0, 841.0, 854.0, 689.0, 559.0, 510.0, 997...  \n",
      "\n",
      "[181 rows x 3 columns]\n",
      "yearly\n",
      "6\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Example of usage\n",
    "loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"m1_yearly_dataset.tsf\")\n",
    "\n",
    "print(loaded_data)\n",
    "print(frequency)\n",
    "print(forecast_horizon)\n",
    "print(contain_missing_values)\n",
    "print(contain_equal_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_name</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>series_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>[3600.0, 7700.0, 12300.0, 30500.0, 47390.0, 57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[12654.0, 22879.0, 34164.0, 49524.0, 64761.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[2142.0, 12935.0, 19130.0, 30500.0, 48177.0, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[5774.0, 7650.0, 9271.0, 21447.0, 28998.0, 409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>1976-01-01</td>\n",
       "      <td>[432312.0, 569011.0, 862673.0, 1155640.0, 1439...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  series_name start_timestamp  \\\n",
       "0          T1      1972-01-01   \n",
       "1          T2      1974-01-01   \n",
       "2          T3      1974-01-01   \n",
       "3          T4      1974-01-01   \n",
       "4          T5      1976-01-01   \n",
       "\n",
       "                                        series_value  \n",
       "0  [3600.0, 7700.0, 12300.0, 30500.0, 47390.0, 57...  \n",
       "1  [12654.0, 22879.0, 34164.0, 49524.0, 64761.0, ...  \n",
       "2  [2142.0, 12935.0, 19130.0, 30500.0, 48177.0, 5...  \n",
       "3  [5774.0, 7650.0, 9271.0, 21447.0, 28998.0, 409...  \n",
       "4  [432312.0, 569011.0, 862673.0, 1155640.0, 1439...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "check_is_scitype() missing 1 required positional argument: 'scitype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/01/4mysj8cx1bjg_w8rbw097jwr0000gp/T/ipykernel_86559/1048451860.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msktime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatatypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_scitype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcheck_is_scitype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: check_is_scitype() missing 1 required positional argument: 'scitype'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#import sktime\n",
    "#from sktime.utils.data_io import load_from_tsfile_to_dataframe\n",
    "from sktime.datatypes import check_is_scitype\n",
    "\n",
    "check_is_scitype(loaded_data)\n",
    "\n",
    "\n",
    "\n",
    "#DATA_PATH = os.path.join(os.path.dirname(sktime.__file__), \"datasets/data\")\n",
    "\n",
    "# train_x, train_y = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"ArrowHead/ArrowHead_TRAIN.ts\")\n",
    "# )\n",
    "# test_x, test_y = load_from_tsfile_to_dataframe(\n",
    "#     os.path.join(DATA_PATH, \"ArrowHead/ArrowHead_TEST.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_name</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>series_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>[3600.0, 7700.0, 12300.0, 30500.0, 47390.0, 57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[12654.0, 22879.0, 34164.0, 49524.0, 64761.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[2142.0, 12935.0, 19130.0, 30500.0, 48177.0, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[5774.0, 7650.0, 9271.0, 21447.0, 28998.0, 409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>1976-01-01</td>\n",
       "      <td>[432312.0, 569011.0, 862673.0, 1155640.0, 1439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>T177</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>[290783.0, 285242.0, 293718.0, 295804.0, 29458...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>T178</td>\n",
       "      <td>1973-01-01</td>\n",
       "      <td>[11693.0, 11702.0, 11703.0, 11557.0, 11951.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>T179</td>\n",
       "      <td>1973-01-01</td>\n",
       "      <td>[8438.0, 8689.0, 8590.0, 8763.0, 8710.0, 8837....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>T180</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>[55.91, 54.7, 55.3, 55.75, 55.46, 55.37, 53.82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>T181</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>[564.0, 841.0, 854.0, 689.0, 559.0, 510.0, 997...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    series_name start_timestamp  \\\n",
       "0            T1      1972-01-01   \n",
       "1            T2      1974-01-01   \n",
       "2            T3      1974-01-01   \n",
       "3            T4      1974-01-01   \n",
       "4            T5      1976-01-01   \n",
       "..          ...             ...   \n",
       "176        T177      1974-01-01   \n",
       "177        T178      1973-01-01   \n",
       "178        T179      1973-01-01   \n",
       "179        T180      1975-01-01   \n",
       "180        T181      1975-01-01   \n",
       "\n",
       "                                          series_value  \n",
       "0    [3600.0, 7700.0, 12300.0, 30500.0, 47390.0, 57...  \n",
       "1    [12654.0, 22879.0, 34164.0, 49524.0, 64761.0, ...  \n",
       "2    [2142.0, 12935.0, 19130.0, 30500.0, 48177.0, 5...  \n",
       "3    [5774.0, 7650.0, 9271.0, 21447.0, 28998.0, 409...  \n",
       "4    [432312.0, 569011.0, 862673.0, 1155640.0, 1439...  \n",
       "..                                                 ...  \n",
       "176  [290783.0, 285242.0, 293718.0, 295804.0, 29458...  \n",
       "177  [11693.0, 11702.0, 11703.0, 11557.0, 11951.0, ...  \n",
       "178  [8438.0, 8689.0, 8590.0, 8763.0, 8710.0, 8837....  \n",
       "179  [55.91, 54.7, 55.3, 55.75, 55.46, 55.37, 53.82...  \n",
       "180  [564.0, 841.0, 854.0, 689.0, 559.0, 510.0, 997...  \n",
       "\n",
       "[181 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yearly'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_name</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>series_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>[3600.0, 7700.0, 12300.0, 30500.0, 47390.0, 57...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  series_name start_timestamp  \\\n",
       "0          T1      1972-01-01   \n",
       "\n",
       "                                        series_value  \n",
       "0  [3600.0, 7700.0, 12300.0, 30500.0, 47390.0, 57...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = loaded_data.head(1)\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181it [00:00, 1246.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1</td>\n",
       "      <td>1973-01-01</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1</td>\n",
       "      <td>1974-01-01</td>\n",
       "      <td>12300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>30500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T1</td>\n",
       "      <td>1976-01-01</td>\n",
       "      <td>47390.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds   values\n",
       "0        T1 1972-01-01   3600.0\n",
       "1        T1 1973-01-01   7700.0\n",
       "2        T1 1974-01-01  12300.0\n",
       "3        T1 1975-01-01  30500.0\n",
       "4        T1 1976-01-01  47390.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "parsed_df = pd.DataFrame()\n",
    "\n",
    "#freq = frequency\n",
    "if frequency == 'yearly':\n",
    "    freq = 'YS' #year start\n",
    "elif frequency == 'quarterly':\n",
    "    freq = 'QS' #quarter start\n",
    "elif frequency == 'monthly':\n",
    "    freq = 'MS'\n",
    "\n",
    "\n",
    "for index,row in tqdm(loaded_data.iterrows()):\n",
    "    \n",
    "    name = row.series_name\n",
    "    #print(name)\n",
    "    values = row.series_value.tolist()\n",
    "    length = len(values)\n",
    "    start = row.start_timestamp\n",
    "    #print(length)\n",
    "    ds = pd.date_range(start, periods=length, freq=freq)\n",
    "    \n",
    "    series_df = pd.DataFrame({'unique_id':name,'ds':ds, 'values':values})\n",
    "    parsed_df = pd.concat([parsed_df, series_df], axis=0)\n",
    "    \n",
    "parsed_df.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_monash_df(file):\n",
    "    \n",
    "    loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(file)\n",
    "\n",
    "    parsed_df = pd.DataFrame()\n",
    "\n",
    "    #freq = frequency\n",
    "    if frequency == 'yearly':\n",
    "        freq = 'YS' #year start\n",
    "    elif frequency == 'quarterly':\n",
    "        freq = 'QS' #quarter start\n",
    "    elif frequency == 'monthly':\n",
    "        freq = 'MS'\n",
    "    elif frequency == 'daily':\n",
    "        freq = 'D'\n",
    "\n",
    "\n",
    "    for index,row in tqdm(loaded_data.iterrows()):\n",
    "        \n",
    "        name = row.series_name\n",
    "        #print(name)\n",
    "        values = row.series_value.tolist()\n",
    "        length = len(values)\n",
    "        start = row.start_timestamp\n",
    "        #print(length)\n",
    "        ds = pd.date_range(start, periods=length, freq=freq)\n",
    "        \n",
    "        series_df = pd.DataFrame({'unique_id':name,'ds':ds, 'values':values})\n",
    "        parsed_df = pd.concat([parsed_df, series_df], axis=0)\n",
    "        \n",
    "    return parsed_df\n",
    "\n",
    "#parse_monash_df(\"m1_yearly_dataset.tsf\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tidal-pulse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "914ceb58c6ac842b05884c1be4a2ad0b416b6dbedaf25f0bde18e10f251005c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
