{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Dataset</th><th>Domain</th><th>No: of Series</th><th>Min. Length</th><th>Max. Length</th><th>Competition</th><th>Multivariate</th><th>Download</th><th>Source</th><th>URL</th><th>Frequency</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>M1</td><td>Multiple</td><td>1001</td><td>15</td><td>150</td><td>Yes</td><td>No</td><td>Yearly</td><td>Makridakis et al., 1982</td><td>https://zenodo.org/record/4656193</td><td>Yearly</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>M1</td><td>Multiple</td><td>1001</td><td>15</td><td>150</td><td>Yes</td><td>No</td><td>Quarterly</td><td>Makridakis et al., 1982</td><td>https://zenodo.org/record/4656154</td><td>Quarterly</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>M1</td><td>Multiple</td><td>1001</td><td>15</td><td>150</td><td>Yes</td><td>No</td><td>Monthly</td><td>Makridakis et al., 1982</td><td>https://zenodo.org/record/4656159</td><td>Monthly</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>M3</td><td>Multiple</td><td>3003</td><td>20</td><td>144</td><td>Yes</td><td>No</td><td>Yearly</td><td>Makridakis and Hibon, 2000</td><td>https://zenodo.org/record/4656222</td><td>Yearly</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>M3</td><td>Multiple</td><td>3003</td><td>20</td><td>144</td><td>Yes</td><td>No</td><td>Quarterly</td><td>Makridakis and Hibon, 2000</td><td>https://zenodo.org/record/4656262</td><td>Quarterly</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>M3</td><td>Multiple</td><td>3003</td><td>20</td><td>144</td><td>Yes</td><td>No</td><td>Monthly</td><td>Makridakis and Hibon, 2000</td><td>https://zenodo.org/record/4656298</td><td>Monthly</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>M3</td><td>Multiple</td><td>3003</td><td>20</td><td>144</td><td>Yes</td><td>No</td><td>Other</td><td>Makridakis and Hibon, 2000</td><td>https://zenodo.org/record/4656335</td><td>Other</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>M4</td><td>Multiple</td><td>100000</td><td>19</td><td>9933</td><td>Yes</td><td>No</td><td>Yearly</td><td>Makridakis et al., 2020</td><td>https://zenodo.org/record/4656379</td><td>Yearly</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>M4</td><td>Multiple</td><td>100000</td><td>19</td><td>9933</td><td>Yes</td><td>No</td><td>Quarterly</td><td>Makridakis et al., 2020</td><td>https://zenodo.org/record/4656410</td><td>Quarterly</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>M4</td><td>Multiple</td><td>100000</td><td>19</td><td>9933</td><td>Yes</td><td>No</td><td>Monthly</td><td>Makridakis et al., 2020</td><td>https://zenodo.org/record/4656480</td><td>Monthly</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>10 rows &times; 11 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#7fed485b1270 10x11>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import urllib\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "from datetime import datetime\n",
    "import time \n",
    "from distutils.util import strtobool\n",
    "\n",
    "import datatable as dt \n",
    "import pandas as pd \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename=f'ingest-{round(time.time())}.log', encoding='utf-8', level=logging.INFO)\n",
    "\n",
    "# Read in Data Frame\n",
    "df = dt.fread(\"monash-repository.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://zenodo.org/record/4656193'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['URL'][0]\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_tsf_to_dataframe(full_file_path_and_name, replace_missing_vals_with=\"NaN\", value_column_name=\"series_value\"):\n",
    "    '''\n",
    "    Converts the contents in a .tsf file into a dataframe and returns it along with other meta-data of the dataset.\n",
    "    \n",
    "        Parameters:\n",
    "            full_file_path_and_name (str): complete .tsf file path\n",
    "            replace_missing_vals_with (str): a term to indicate the missing values in series in the returning dataframe\n",
    "            value_column_name (str): Any name that is preferred to have as the name of the column containing series values in the returning dataframe\n",
    "    \n",
    "        Returns:\n",
    "            data (pd.DataFrame): load data frame\n",
    "            frequency (str): time series frequency\n",
    "            horizon (int): time series forecasting horizon\n",
    "            missing (bool): whether the dataset contains missing values\n",
    "            equal (bool): whether the series have equal lengths\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    col_names = []\n",
    "    col_types = []\n",
    "    all_data = {}\n",
    "    line_count = 0\n",
    "    frequency = None\n",
    "    forecast_horizon = None\n",
    "    contain_missing_values = None\n",
    "    contain_equal_length = None\n",
    "    found_data_tag = False\n",
    "    found_data_section = False\n",
    "    started_reading_data_section = False\n",
    "\n",
    "    with open(full_file_path_and_name, \"r\", encoding=\"cp1252\") as file:\n",
    "        for line in file:\n",
    "            # Strip white space from start/end of line\n",
    "            line = line.strip()\n",
    "\n",
    "            if line:\n",
    "                if line.startswith(\"@\"):  # Read meta-data\n",
    "                    if not line.startswith(\"@data\"):\n",
    "                        line_content = line.split(\" \")\n",
    "                        if line.startswith(\"@attribute\"):\n",
    "                            if (\n",
    "                                len(line_content) != 3\n",
    "                            ):  # Attributes have both name and type\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            col_names.append(line_content[1])\n",
    "                            col_types.append(line_content[2])\n",
    "                        else:\n",
    "                            if (\n",
    "                                len(line_content) != 2\n",
    "                            ):  # Other meta-data have only values\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            if line.startswith(\"@frequency\"):\n",
    "                                frequency = line_content[1]\n",
    "                            elif line.startswith(\"@horizon\"):\n",
    "                                forecast_horizon = int(line_content[1])\n",
    "                            elif line.startswith(\"@missing\"):\n",
    "                                contain_missing_values = bool(\n",
    "                                    strtobool(line_content[1])\n",
    "                                )\n",
    "                            elif line.startswith(\"@equallength\"):\n",
    "                                contain_equal_length = bool(strtobool(line_content[1]))\n",
    "\n",
    "                    else:\n",
    "                        if len(col_names) == 0:\n",
    "                            raise Exception(\n",
    "                                \"Missing attribute section. Attribute section must come before data.\"\n",
    "                            )\n",
    "\n",
    "                        found_data_tag = True\n",
    "                elif not line.startswith(\"#\"):\n",
    "                    if len(col_names) == 0:\n",
    "                        raise Exception(\n",
    "                            \"Missing attribute section. Attribute section must come before data.\"\n",
    "                        )\n",
    "                    elif not found_data_tag:\n",
    "                        raise Exception(\"Missing @data tag.\")\n",
    "                    else:\n",
    "                        if not started_reading_data_section:\n",
    "                            started_reading_data_section = True\n",
    "                            found_data_section = True\n",
    "                            all_series = []\n",
    "\n",
    "                            for col in col_names:\n",
    "                                all_data[col] = []\n",
    "\n",
    "                        full_info = line.split(\":\")\n",
    "\n",
    "                        if len(full_info) != (len(col_names) + 1):\n",
    "                            raise Exception(\"Missing attributes/values in series.\")\n",
    "\n",
    "                        series = full_info[len(full_info) - 1]\n",
    "                        series = series.split(\",\")\n",
    "\n",
    "                        if len(series) == 0:\n",
    "                            raise Exception(\n",
    "                                \"A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series. Missing values should be indicated with ? symbol\"\n",
    "                            )\n",
    "\n",
    "                        numeric_series = []\n",
    "\n",
    "                        for val in series:\n",
    "                            if val == \"?\":\n",
    "                                numeric_series.append(replace_missing_vals_with)\n",
    "                            else:\n",
    "                                numeric_series.append(float(val))\n",
    "\n",
    "                        if numeric_series.count(replace_missing_vals_with) == len(\n",
    "                            numeric_series\n",
    "                        ):\n",
    "                            raise Exception(\n",
    "                                \"All series values are missing. A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series.\"\n",
    "                            )\n",
    "\n",
    "                        all_series.append(pd.Series(numeric_series).array)\n",
    "\n",
    "                        for i in range(len(col_names)):\n",
    "                            att_val = None\n",
    "                            if col_types[i] == \"numeric\":\n",
    "                                att_val = int(full_info[i])\n",
    "                            elif col_types[i] == \"string\":\n",
    "                                att_val = str(full_info[i])\n",
    "                            elif col_types[i] == \"date\":\n",
    "                                att_val = datetime.strptime(\n",
    "                                    full_info[i], \"%Y-%m-%d %H-%M-%S\"\n",
    "                                )\n",
    "                            else:\n",
    "                                raise Exception(\n",
    "                                    \"Invalid attribute type.\"\n",
    "                                )  # Currently, the code supports only numeric, string and date types. Extend this as required.\n",
    "\n",
    "                            if att_val is None:\n",
    "                                raise Exception(\"Invalid attribute value.\")\n",
    "                            else:\n",
    "                                all_data[col_names[i]].append(att_val)\n",
    "\n",
    "                line_count = line_count + 1\n",
    "\n",
    "        if line_count == 0:\n",
    "            raise Exception(\"Empty file.\")\n",
    "        if len(col_names) == 0:\n",
    "            raise Exception(\"Missing attribute section.\")\n",
    "        if not found_data_section:\n",
    "            raise Exception(\"Missing series information under data section.\")\n",
    "\n",
    "        all_data[value_column_name] = all_series\n",
    "        loaded_data = pd.DataFrame(all_data)\n",
    "\n",
    "        return (\n",
    "            loaded_data,\n",
    "            frequency,\n",
    "            forecast_horizon,\n",
    "            contain_missing_values,\n",
    "            contain_equal_length,\n",
    "        )\n",
    "\n",
    "def parse_monash_df(file):\n",
    "    ''' Function to Parse a Locally Extracted and Downloaded File'''\n",
    "    \n",
    "    loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(file)\n",
    "\n",
    "    logging.info(f'PARSING FILE: {file}...')\n",
    "    logging.info(f\"IDENTIFIED FREQUENCY: {frequency}...\")\n",
    "    logging.info(f\"IDENTIFIED FORECAST HORIZON: {forecast_horizon}\")\n",
    "\n",
    "    parsed_df = pd.DataFrame()\n",
    "\n",
    "    #freq = frequency\n",
    "    if frequency == 'yearly':\n",
    "        freq = 'YS' #year start\n",
    "    elif frequency == 'quarterly':\n",
    "        freq = 'QS' #quarter start\n",
    "    elif frequency == 'monthly':\n",
    "        freq = 'MS'\n",
    "    elif frequency == 'daily':\n",
    "        freq = 'D'\n",
    "\n",
    "\n",
    "    for index,row in tqdm(loaded_data.iterrows()):\n",
    "        \n",
    "        name = row.series_name\n",
    "        #print(name)\n",
    "        values = row.series_value.tolist()\n",
    "        length = len(values)\n",
    "        start = row.start_timestamp\n",
    "        \n",
    "        #print(f'STARTING TIMESTAMP: {start}')\n",
    "        #$print(f'TIMESERIES LENGTH: {length}')\n",
    "        \n",
    "        #print(length)\n",
    "        try:\n",
    "            ds = pd.date_range(start, periods=length, freq=freq)\n",
    "            series_df = pd.DataFrame({'unique_id':name,'ds':ds, 'values':values})\n",
    "        except:\n",
    "            logging.warning(f'FAILED PARSING TIMESERIES: {name}')\n",
    "            series_df = pd.DataFrame()\n",
    "            \n",
    "        #convert date range to datetime and automatically coerce errors\n",
    "        #ds = pd.to_datetime(ds, errors = 'coerce')\n",
    "\n",
    "        \n",
    "        #series_df = pd.DataFrame({'unique_id':name,'ds':ds, 'values':values})\n",
    "        parsed_df = pd.concat([parsed_df, series_df], axis=0)\n",
    "        \n",
    "    return parsed_df\n",
    "\n",
    "# Example Usage\n",
    "#parse_monash_df(\"m1_yearly_dataset.tsf\").head()\n",
    "\n",
    "def retrieve_monash_df(url):\n",
    "    \n",
    "    # Create Soup\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    # Create Soup\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    # Find Download URL from Filename Class\n",
    "    info = soup.select(\"[class~=filename]\")\n",
    "    \n",
    "    # Parse Download Url\n",
    "    download_url = info[0].get('href')\n",
    "    \n",
    "    # Download File\n",
    "    urllib.request.urlretrieve(\"https://zenodo.org\" + download_url, \"tmp.zip\")\n",
    "    \n",
    "# Example Usage\n",
    "#retrieve_monash_df(df['URL'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Domain</th>\n",
       "      <th>No: of Series</th>\n",
       "      <th>Min. Length</th>\n",
       "      <th>Max. Length</th>\n",
       "      <th>Competition</th>\n",
       "      <th>Multivariate</th>\n",
       "      <th>Download</th>\n",
       "      <th>Source</th>\n",
       "      <th>URL</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M4</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>100000</td>\n",
       "      <td>19</td>\n",
       "      <td>9933</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Makridakis et al., 2020</td>\n",
       "      <td>https://zenodo.org/record/4656548</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Weather</td>\n",
       "      <td>Nature</td>\n",
       "      <td>3010</td>\n",
       "      <td>1332</td>\n",
       "      <td>65981</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Sparks et al., 2020</td>\n",
       "      <td>https://zenodo.org/record/4654822</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>COVID Deaths</td>\n",
       "      <td>Nature</td>\n",
       "      <td>266</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Johns Hopkins University, 2020</td>\n",
       "      <td>https://zenodo.org/record/4656009</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Saugeen River Flow</td>\n",
       "      <td>Nature</td>\n",
       "      <td>1</td>\n",
       "      <td>23741</td>\n",
       "      <td>23741</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Daily</td>\n",
       "      <td>McLeod and Gweon, 2013</td>\n",
       "      <td>https://zenodo.org/record/4656058</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>US Births</td>\n",
       "      <td>Nature</td>\n",
       "      <td>1</td>\n",
       "      <td>7305</td>\n",
       "      <td>7305</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Pruim et al., 2020</td>\n",
       "      <td>https://zenodo.org/record/4656049</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset    Domain  No: of Series  Min. Length  Max. Length  \\\n",
       "11                  M4  Multiple         100000           19         9933   \n",
       "30             Weather    Nature           3010         1332        65981   \n",
       "49        COVID Deaths    Nature            266          212          212   \n",
       "54  Saugeen River Flow    Nature              1        23741        23741   \n",
       "55           US Births    Nature              1         7305         7305   \n",
       "\n",
       "   Competition Multivariate Download                          Source  \\\n",
       "11         Yes           No    Daily         Makridakis et al., 2020   \n",
       "30          No           No    Daily             Sparks et al., 2020   \n",
       "49          No          Yes    Daily  Johns Hopkins University, 2020   \n",
       "54          No           No    Daily          McLeod and Gweon, 2013   \n",
       "55          No           No    Daily              Pruim et al., 2020   \n",
       "\n",
       "                                  URL Frequency  \n",
       "11  https://zenodo.org/record/4656548     Daily  \n",
       "30  https://zenodo.org/record/4654822     Daily  \n",
       "49  https://zenodo.org/record/4656009     Daily  \n",
       "54  https://zenodo.org/record/4656058     Daily  \n",
       "55  https://zenodo.org/record/4656049     Daily  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Focus on just a few datasets\n",
    "df = df[df['Frequency'].isin(['Daily'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jfarland/Documents/research/timeseries-benchmarks/data'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path = '/Users/jfarland/Documents/research/timeseries-benchmarks'\n",
    "data_path = project_path + '/data'\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Dataset    Domain  No: of Series  Min. Length  Max. Length  \\\n",
      "0                   M1  Multiple           1001           15          150   \n",
      "2                   M1  Multiple           1001           15          150   \n",
      "3                   M3  Multiple           3003           20          144   \n",
      "5                   M3  Multiple           3003           20          144   \n",
      "7                   M4  Multiple         100000           19         9933   \n",
      "9                   M4  Multiple         100000           19         9933   \n",
      "11                  M4  Multiple         100000           19         9933   \n",
      "13             Tourism   Tourism           1311           11          333   \n",
      "15             Tourism   Tourism           1311           11          333   \n",
      "16            CIF 2016   Banking             72           34          120   \n",
      "30             Weather    Nature           3010         1332        65981   \n",
      "43             FRED-MD  Economic            107          728          728   \n",
      "48            Hospital    Health            767           84           84   \n",
      "49        COVID Deaths    Nature            266          212          212   \n",
      "54  Saugeen River Flow    Nature              1        23741        23741   \n",
      "55           US Births    Nature              1         7305         7305   \n",
      "\n",
      "   Competition Multivariate Download                          Source  \\\n",
      "0          Yes           No   Yearly         Makridakis et al., 1982   \n",
      "2          Yes           No  Monthly         Makridakis et al., 1982   \n",
      "3          Yes           No   Yearly      Makridakis and Hibon, 2000   \n",
      "5          Yes           No  Monthly      Makridakis and Hibon, 2000   \n",
      "7          Yes           No   Yearly         Makridakis et al., 2020   \n",
      "9          Yes           No  Monthly         Makridakis et al., 2020   \n",
      "11         Yes           No    Daily         Makridakis et al., 2020   \n",
      "13         Yes           No   Yearly     Athanasopoulos et al., 2011   \n",
      "15         Yes           No  Monthly     Athanasopoulos et al., 2011   \n",
      "16         Yes           No  Monthly       Stepnicka and Burda, 2017   \n",
      "30          No           No    Daily             Sparks et al., 2020   \n",
      "43          No          Yes  Monthly          McCracken and Ng, 2016   \n",
      "48          No          Yes  Monthly                   Hyndman, 2015   \n",
      "49          No          Yes    Daily  Johns Hopkins University, 2020   \n",
      "54          No           No    Daily          McLeod and Gweon, 2013   \n",
      "55          No           No    Daily              Pruim et al., 2020   \n",
      "\n",
      "                                  URL Frequency  \n",
      "0   https://zenodo.org/record/4656193    Yearly  \n",
      "2   https://zenodo.org/record/4656159   Monthly  \n",
      "3   https://zenodo.org/record/4656222    Yearly  \n",
      "5   https://zenodo.org/record/4656298   Monthly  \n",
      "7   https://zenodo.org/record/4656379    Yearly  \n",
      "9   https://zenodo.org/record/4656480   Monthly  \n",
      "11  https://zenodo.org/record/4656548     Daily  \n",
      "13  https://zenodo.org/record/4656103    Yearly  \n",
      "15  https://zenodo.org/record/4656096   Monthly  \n",
      "16  https://zenodo.org/record/4656042   Monthly  \n",
      "30  https://zenodo.org/record/4654822     Daily  \n",
      "43  https://zenodo.org/record/4654833   Monthly  \n",
      "48  https://zenodo.org/record/4656014   Monthly  \n",
      "49  https://zenodo.org/record/4656009     Daily  \n",
      "54  https://zenodo.org/record/4656058     Daily  \n",
      "55  https://zenodo.org/record/4656049     Daily  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181it [00:00, 1411.58it/s]\n",
      "617it [00:00, 789.93it/s]\n",
      "645it [00:00, 1343.79it/s]\n",
      "1428it [00:02, 575.86it/s]\n",
      "23000it [01:25, 270.06it/s]\n",
      "48000it [43:40, 18.32it/s]\n",
      "4227it [05:54, 11.91it/s]\n",
      "518it [00:00, 1348.63it/s]\n",
      "366it [00:01, 353.94it/s]\n",
      "0it [00:00, ?it/s]s/it]\n",
      "9it [54:54, 366.02s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'start_timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/01/4mysj8cx1bjg_w8rbw097jwr0000gp/T/ipykernel_84547/3834994954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Parse the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mlocal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_monash_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Convert to DataTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/01/4mysj8cx1bjg_w8rbw097jwr0000gp/T/ipykernel_84547/2555876003.py\u001b[0m in \u001b[0;36mparse_monash_df\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_timestamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m#print(f'STARTING TIMESTAMP: {start}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tidal-pulse/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5904\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'start_timestamp'"
     ]
    }
   ],
   "source": [
    "# limit to 1 data set\n",
    "sample_df = df[df['Frequency'].isin(['Daily', 'Monthly', 'Yearly'])]\n",
    "\n",
    "#sample_df = sample_df[sample_df['Multivariate']=='Yes']\n",
    "#sample_df = sample_df[(sample_df['Download']=='Yearly') & (sample_df['Dataset'] == 'M4')]\n",
    "\n",
    "print(sample_df)\n",
    "\n",
    "for index, row in tqdm(sample_df.iterrows()):\n",
    "    \n",
    "    # Make sure current directory is data directory\n",
    "    os.chdir(data_path)\n",
    "    \n",
    "    # Remove Archive File if it already exists in \n",
    "    if os.path.exists(data_path + '/tmp.zip'):\n",
    "        logging.info(f'DELETING EXISTING ARCHIVE FILE...')\n",
    "        os.remove(data_path + '/tmp.zip')\n",
    "        \n",
    "    # Identify url from mapping file\n",
    "    url = row.URL\n",
    "    logging.info(f'RETRIEVING URL: {url}')\n",
    "    \n",
    "    # Retrieve the file from the url\n",
    "    retrieve_monash_df(url)\n",
    "    \n",
    "    if not os.path.exists('staging'):\n",
    "        logging.info(\"STAGING DIRECTORY NOT FOUND, CREATING NEW ONE...\")\n",
    "        os.makedirs('staging')\n",
    "    else:\n",
    "        try:\n",
    "            logging.info(\"STAGING DIRECTORY FOUND, CLEANING AND RECREATING...\")\n",
    "            shutil.rmtree('staging')\n",
    "            os.makedirs('staging')\n",
    "        except OSError as e:\n",
    "            logging.warning(\"Error: %s : %s\" % (dest, e.strerror))\n",
    "        \n",
    "    # Copy Archive File into Staging Directory\n",
    "    shutil.copy('tmp.zip', 'staging')\n",
    "    \n",
    "    # Go into the directory and unpack\n",
    "    os.chdir('staging')\n",
    "        \n",
    "    shutil.unpack_archive('tmp.zip')\n",
    "    \n",
    "    # Find any TSF Files\n",
    "    result = glob.glob('*.{}'.format('tsf'))\n",
    "    \n",
    "    # Find the name of the file \n",
    "    local_name = result[0].split(\".\")[0]\n",
    "    logging.info(f'DATASET NAME: {local_name}...')\n",
    "    \n",
    "    # Parse the DataFrame\n",
    "    local_df = parse_monash_df(result[0])\n",
    "    \n",
    "    # Convert to DataTable\n",
    "    local_df = dt.Frame(local_df)\n",
    "    \n",
    "    os.chdir(data_path)\n",
    "    \n",
    "    if not os.path.exists(local_name):\n",
    "        logging.info(\"DATASET DIRECTORY NOT FOUND, CREATING NEW ONE...\")\n",
    "        os.makedirs(local_name)\n",
    "    else:\n",
    "        try:\n",
    "            logging.info(\"DATASET DIRECTORY FOUND, CLEANING AND RECREATING...\")\n",
    "            shutil.rmtree(local_name)\n",
    "            os.makedirs(local_name)\n",
    "        except OSError as e:\n",
    "            logging.warning(\"Error: %s : %s\" % (dest, e.strerror))\n",
    "        \n",
    "    local_df.to_csv(local_name + '/' + local_name + '.csv')\n",
    "    \n",
    "    \n",
    " \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tidal-pulse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "914ceb58c6ac842b05884c1be4a2ad0b416b6dbedaf25f0bde18e10f251005c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
